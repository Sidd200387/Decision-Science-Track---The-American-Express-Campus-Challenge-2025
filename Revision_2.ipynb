{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9479e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import duckdb\n",
    "\n",
    "# os.chdir(r\"C:\\Users\\siddu\\Desktop\\Decision Science Track\\Revision\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54227b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload filepaths\n",
    "train_data_fp = r\"C:\\Users\\siddu\\Desktop\\Decision Science Track\\Revision\\train_data_merged.parquet\"\n",
    "test_data_fp = r\"C:\\Users\\siddu\\Desktop\\Decision Science Track\\Revision\\test_data_merged.parquet\"\n",
    "\n",
    "# Load files into dataframes\n",
    "train_data_df = pd.read_parquet(train_data_fp)\n",
    "test_data_df = pd.read_parquet(test_data_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b92b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for number of rows and columns\n",
    "print(train_data_df.shape)\n",
    "print(test_data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f9bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check consistency of datatypes of train and test\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Assuming your DataFrames are loaded ---\n",
    "# train_data_df = ...\n",
    "# test_data_df = ...\n",
    "\n",
    "\n",
    "## 1. Group DataFrames for easy checking\n",
    "# Use a dictionary to map a name to the DataFrame object\n",
    "dataframes_to_check = {\n",
    "    'train': train_data_df,\n",
    "    'test': test_data_df\n",
    "}\n",
    "\n",
    "## 2. NEW: Automatically build the list of ALL unique columns\n",
    "print(\"Finding all unique columns across datasets...\")\n",
    "all_columns_set = set()\n",
    "for df in dataframes_to_check.values():\n",
    "    # .update() adds all columns from the DataFrame to the set\n",
    "    all_columns_set.update(df.columns)\n",
    "\n",
    "# Use this comprehensive list as your new cols_to_check\n",
    "# Sorting makes the final report easier to read\n",
    "cols_to_check = sorted(list(all_columns_set))\n",
    "print(f\"Found {len(cols_to_check)} unique columns to check.\")\n",
    "\n",
    "\n",
    "## 3. Store findings in a dictionary\n",
    "# The key will be the column name\n",
    "# The value will be a set of all dtypes found\n",
    "column_dtypes = defaultdict(set)\n",
    "\n",
    "## 4. Iterate and check\n",
    "print(\"\\nChecking column data types...\")\n",
    "for col in cols_to_check:\n",
    "    for df_name, df in dataframes_to_check.items():\n",
    "        # Check if the column exists in the DataFrame\n",
    "        if col in df.columns:\n",
    "            # If it exists, add its dtype (as a string) to the set\n",
    "            column_dtypes[col].add(str(df[col].dtype))\n",
    "\n",
    "## 5. Report the results\n",
    "print(\"\\n--- Dtype Consistency Report ---\")\n",
    "inconsistent_cols = []\n",
    "\n",
    "for col, dtypes in column_dtypes.items():\n",
    "    # Note: A column will ONLY show up here if it exists\n",
    "    # in at least one of the DataFrames.\n",
    "    \n",
    "    if len(dtypes) == 1:\n",
    "        # Only one dtype was found, so it's consistent\n",
    "        print(f\"✅ {col:<20} | Consistent: {list(dtypes)[0]}\")\n",
    "    else:\n",
    "        # More than one dtype was found, this is an inconsistency\n",
    "        print(f\"⚠️ {col:<20} | INCONSISTENT: {dtypes}\")\n",
    "        inconsistent_cols.append(col)\n",
    "\n",
    "print(\"\\n--- Summary ---\")\n",
    "if not inconsistent_cols:\n",
    "    print(\"All checked columns are consistent across datasets.\")\n",
    "else:\n",
    "    print(f\"Found {len(inconsistent_cols)} inconsistent columns: {inconsistent_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff4053",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_df.dtypes)\n",
    "print(test_data_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1996401",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_df.info())\n",
    "print(test_data_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def profile_object_columns(df, df_name):\n",
    "    \"\"\"\n",
    "    Profiles all 'object' columns in a DataFrame for common data quality issues\n",
    "    and returns a DataFrame of the findings.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Profiling 'object' columns in {df_name} ---\")\n",
    "    \n",
    "    object_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    if len(object_cols) == 0:\n",
    "        print(\"No 'object' columns found to profile.\")\n",
    "        # Return an empty DataFrame if no object columns\n",
    "        return pd.DataFrame() \n",
    "\n",
    "    print(f\"Found {len(object_cols)} 'object' columns to check.\")\n",
    "    \n",
    "    null_like_values = ['null', 'Null', 'NULL', 'nan', 'NaN', 'NA', 'N/A', 'None', '']\n",
    "\n",
    "    cleanliness_report = []\n",
    "    \n",
    "    for col in object_cols:\n",
    "        series_as_str = df[col].astype(str)\n",
    "        \n",
    "        # Check 1: Whitespace\n",
    "        whitespace_count = (series_as_str != series_as_str.str.strip()).sum()\n",
    "        \n",
    "        # Check 2: Null-like strings\n",
    "        null_like_count = df[col].isin(null_like_values).sum()\n",
    "        \n",
    "        # Check 3: Case Inconsistency\n",
    "        nunique = series_as_str.nunique()\n",
    "        nunique_lower = series_as_str.str.lower().nunique()\n",
    "        case_issue = (nunique != nunique_lower)\n",
    "        \n",
    "        # Check 4: Real NaN count\n",
    "        real_nan_count = df[col].isnull().sum()\n",
    "        \n",
    "        cleanliness_report.append({\n",
    "            'column': col,\n",
    "            'real_nan_count': real_nan_count,\n",
    "            'whitespace_count': whitespace_count,\n",
    "            'null_like_strings_count': null_like_count,\n",
    "            'has_case_inconsistency': case_issue\n",
    "        })\n",
    "\n",
    "    report_df = pd.DataFrame(cleanliness_report)\n",
    "    \n",
    "    # Filter to only show columns with issues\n",
    "    dirty_cols_report = report_df[\n",
    "        (report_df['real_nan_count'] > 0) |\n",
    "        (report_df['whitespace_count'] > 0) |\n",
    "        (report_df['null_like_strings_count'] > 0) |\n",
    "        (report_df['has_case_inconsistency'] == True)\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n--- Data Cleanliness Report ---\")\n",
    "    if dirty_cols_report.empty:\n",
    "        print(\"✅ All 'object' columns look clean.\")\n",
    "    else:\n",
    "        print(\"⚠️ Found potential issues in the following 'object' columns:\")\n",
    "        print(dirty_cols_report.to_string(index=False))\n",
    "        \n",
    "    # --- MODIFICATION HERE ---\n",
    "    # Return the report of dirty columns so we can save it\n",
    "    return dirty_cols_report\n",
    "\n",
    "# --- How to use it ---\n",
    "\n",
    "# Assuming train_data_df and test_data_df are loaded\n",
    "\n",
    "# 1. Run the profiler and *capture the returned DataFrames*\n",
    "print(\"Running profiler on training data...\")\n",
    "train_report = profile_object_columns(train_data_df, 'train_data_df')\n",
    "\n",
    "print(\"\\nRunning profiler on test data...\")\n",
    "test_report = profile_object_columns(test_data_df, 'test_data_df')\n",
    "\n",
    "# 2. Define an output Excel file\n",
    "output_excel_file = 'data_cleanliness_report.xlsx'\n",
    "\n",
    "# 3. Use pd.ExcelWriter to save both reports to different sheets\n",
    "print(f\"\\nExporting reports to {output_excel_file}...\")\n",
    "with pd.ExcelWriter(output_excel_file, engine='openpyxl') as writer:\n",
    "    train_report.to_excel(writer, sheet_name='Train Report', index=False)\n",
    "    test_report.to_excel(writer, sheet_name='Test Report', index=False)\n",
    "\n",
    "print(\"✅ Successfully exported reports.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46059c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# The two columns we know have case issues\n",
    "cols_to_fix = ['id8', 'id11']\n",
    "\n",
    "# Your dictionary of dataframes\n",
    "dataframes_to_check = {\n",
    "    'train': train_data_df,\n",
    "    'test': test_data_df\n",
    "}\n",
    "\n",
    "print(\"--- Applying Robust Normalization for 'id8', 'id11' ---\")\n",
    "\n",
    "for df_name, df in dataframes_to_check.items():\n",
    "    print(f\"Checking DataFrame: '{df_name}'.\")\n",
    "    for col in cols_to_fix:\n",
    "        if col in df.columns:\n",
    "            # This is the robust chain that handles NaNs and mixed types\n",
    "            # by converting to string *before* normalizing.\n",
    "            df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "            print(f\"- Column '{col}' robustly normalized.\")\n",
    "\n",
    "print(\"--- Robust Normalization Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c13f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Verifying fix for 'id8' and 'id11' ---\")\n",
    "\n",
    "cols_to_verify = ['id8', 'id11']\n",
    "dataframes_to_check = {\n",
    "    'train_data_df': train_data_df,\n",
    "    'test_data_df': test_data_df\n",
    "}\n",
    "\n",
    "all_fixed = True\n",
    "\n",
    "for df_name, df in dataframes_to_check.items():\n",
    "    print(f\"\\nChecking {df_name}...\")\n",
    "    for col in cols_to_verify:\n",
    "        if col in df.columns:\n",
    "            # Run the *specific* check for case inconsistency\n",
    "            series_as_str = df[col].astype(str)\n",
    "            nunique = series_as_str.nunique()\n",
    "            nunique_lower = series_as_str.str.lower().nunique()\n",
    "            case_issue = (nunique != nunique_lower)\n",
    "            \n",
    "            if case_issue:\n",
    "                print(f\"⚠️ {col:<10} | FAILED: Still has case inconsistency.\")\n",
    "                all_fixed = False\n",
    "            else:\n",
    "                print(f\"✅ {col:<10} | PASSED: Case is now consistent.\")\n",
    "        else:\n",
    "            print(f\"ℹ️ {col:<10} | Not found in this DataFrame.\")\n",
    "            \n",
    "if all_fixed:\n",
    "    print(\"\\n--- Verification Successful ---\")\n",
    "else:\n",
    "    print(\"\\n--- Verification Failed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47724c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def profile_object_columns(df, df_name):\n",
    "    \"\"\"\n",
    "    Profiles all 'object' columns in a DataFrame for common data quality issues\n",
    "    and returns a DataFrame of the findings.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Profiling 'object' columns in {df_name} ---\")\n",
    "    \n",
    "    object_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    if len(object_cols) == 0:\n",
    "        print(\"No 'object' columns found to profile.\")\n",
    "        # Return an empty DataFrame if no object columns\n",
    "        return pd.DataFrame() \n",
    "\n",
    "    print(f\"Found {len(object_cols)} 'object' columns to check.\")\n",
    "    \n",
    "    null_like_values = ['null', 'Null', 'NULL', 'nan', 'NaN', 'NA', 'N/A', 'None', '']\n",
    "\n",
    "    cleanliness_report = []\n",
    "    \n",
    "    for col in object_cols:\n",
    "        series_as_str = df[col].astype(str)\n",
    "        \n",
    "        # Check 1: Whitespace\n",
    "        whitespace_count = (series_as_str != series_as_str.str.strip()).sum()\n",
    "        \n",
    "        # Check 2: Null-like strings\n",
    "        null_like_count = df[col].isin(null_like_values).sum()\n",
    "        \n",
    "        # Check 3: Case Inconsistency\n",
    "        nunique = series_as_str.nunique()\n",
    "        nunique_lower = series_as_str.str.lower().nunique()\n",
    "        case_issue = (nunique != nunique_lower)\n",
    "        \n",
    "        # Check 4: Real NaN count\n",
    "        real_nan_count = df[col].isnull().sum()\n",
    "        \n",
    "        cleanliness_report.append({\n",
    "            'column': col,\n",
    "            'real_nan_count': real_nan_count,\n",
    "            'whitespace_count': whitespace_count,\n",
    "            'null_like_strings_count': null_like_count,\n",
    "            'has_case_inconsistency': case_issue\n",
    "        })\n",
    "\n",
    "    report_df = pd.DataFrame(cleanliness_report)\n",
    "    \n",
    "    # Filter to only show columns with issues\n",
    "    dirty_cols_report = report_df[\n",
    "        (report_df['real_nan_count'] > 0) |\n",
    "        (report_df['whitespace_count'] > 0) |\n",
    "        (report_df['null_like_strings_count'] > 0) |\n",
    "        (report_df['has_case_inconsistency'] == True)\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n--- Data Cleanliness Report ---\")\n",
    "    if dirty_cols_report.empty:\n",
    "        print(\"✅ All 'object' columns look clean.\")\n",
    "    else:\n",
    "        print(\"⚠️ Found potential issues in the following 'object' columns:\")\n",
    "        print(dirty_cols_report.to_string(index=False))\n",
    "        \n",
    "    # --- MODIFICATION HERE ---\n",
    "    # Return the report of dirty columns so we can save it\n",
    "    return dirty_cols_report\n",
    "\n",
    "# --- How to use it ---\n",
    "\n",
    "# Assuming train_data_df and test_data_df are loaded\n",
    "\n",
    "# 1. Run the profiler and *capture the returned DataFrames*\n",
    "print(\"Running profiler on training data...\")\n",
    "train_report = profile_object_columns(train_data_df, 'train_data_df')\n",
    "\n",
    "print(\"\\nRunning profiler on test data...\")\n",
    "test_report = profile_object_columns(test_data_df, 'test_data_df')\n",
    "\n",
    "# 2. Define an output Excel file\n",
    "output_excel_file = 'data_cleanliness_report_1.xlsx'\n",
    "\n",
    "# 3. Use pd.ExcelWriter to save both reports to different sheets\n",
    "print(f\"\\nExporting reports to {output_excel_file}...\")\n",
    "with pd.ExcelWriter(output_excel_file, engine='openpyxl') as writer:\n",
    "    train_report.to_excel(writer, sheet_name='Train Report', index=False)\n",
    "    test_report.to_excel(writer, sheet_name='Test Report', index=False)\n",
    "\n",
    "print(\"✅ Successfully exported reports.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af0906",
   "metadata": {},
   "source": [
    "- Done normalization for all 381(380) object columns in train(test) datasets.\n",
    "- Now check the float ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Assuming train_data_df and test_data_df are loaded ---\n",
    "\n",
    "print(\"--- Float Column Analysis ---\")\n",
    "\n",
    "# 1. Automatically find the float64 columns\n",
    "float_cols_train = train_data_df.select_dtypes(include=['float64']).columns\n",
    "float_cols_test = test_data_df.select_dtypes(include=['float64']).columns\n",
    "\n",
    "print(f\"Train float columns found: {list(float_cols_train)}\")\n",
    "print(f\"Test float columns found: {list(float_cols_test)}\")\n",
    "\n",
    "# 2. Check the columns in train_data_df\n",
    "print(\"\\n--- Train Data Check ---\")\n",
    "if len(float_cols_train) > 0:\n",
    "    # A) Show statistical distribution (mean, min, max, quartiles)\n",
    "    print(\"Distribution Stats:\")\n",
    "    # Using .to_string() for better formatting\n",
    "    print(train_data_df[float_cols_train].describe().to_string())\n",
    "\n",
    "    # B) Check for Missing (NaN) values\n",
    "    print(\"\\nMissing (NaN) Value Counts:\")\n",
    "    print(train_data_df[float_cols_train].isnull().sum())\n",
    "\n",
    "    # C) Check for Infinite (inf) values (common issue)\n",
    "    print(\"\\nInfinite Value Counts:\")\n",
    "    # We use np.isinf and check the sum\n",
    "    print(np.isinf(train_data_df[float_cols_train]).sum())\n",
    "else:\n",
    "    print(\"No float columns found.\")\n",
    "\n",
    "\n",
    "# 3. Check the columns in test_data_df\n",
    "print(\"\\n--- Test Data Check ---\")\n",
    "if len(float_cols_test) > 0:\n",
    "    # A) Show statistical distribution\n",
    "    print(\"Distribution Stats:\")\n",
    "    print(test_data_df[float_cols_test].describe().to_string())\n",
    "\n",
    "    # B) Check for Missing (NaN) values\n",
    "    print(\"\\nMissing (NaN) Value Counts:\")\n",
    "    print(test_data_df[float_cols_test].isnull().sum())\n",
    "    \n",
    "    # C) Check for Infinite (inf) values\n",
    "    print(\"\\nInfinite Value Counts:\")\n",
    "    print(np.isinf(test_data_df[float_cols_test]).sum())\n",
    "else:\n",
    "    print(\"No float columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf95e1",
   "metadata": {},
   "source": [
    "# No mistakes till here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f13611",
   "metadata": {},
   "source": [
    "# Convert columns to their intended formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625567b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column list generator function\n",
    "def generate_column_list(start, end):\n",
    "    # Extract the prefix (non-digit) part\n",
    "    prefix = ''.join([c for c in start if not c.isdigit()])\n",
    "    # Extract the numeric part and convert to int\n",
    "    start_num = int(''.join([c for c in start if c.isdigit()]))\n",
    "    end_num = int(''.join([c for c in end if c.isdigit()]))\n",
    "\n",
    "    # Generate the list using list comprehension\n",
    "    return [f\"{prefix}{i}\" for i in range(start_num, end_num + 1)]\n",
    "\n",
    "# Example usage:\n",
    "binary_cols = generate_column_list('f52', 'f57')\n",
    "print(binary_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa7c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify col types\n",
    "binary_cols = ['f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309']\n",
    "\n",
    "numeric_cols = ['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f43', 'f44', 'f45', 'f46', 'f47', 'f49', 'f50', 'f51','f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f350', 'f351', 'f352', 'f353', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f375', 'f376', 'f377']\n",
    "\n",
    "categorical_cols = ['id3', 'id6', 'id11', 'f42', 'f48', 'f50', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f349', 'f354', 'f374', 'f378']\n",
    "\n",
    "datetime_cols = ['id4', 'id7', 'id12', 'id13', 'id5']\n",
    "\n",
    "object_cols = ['id1', 'id2', 'id9']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f30542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_df.info())\n",
    "print(test_data_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6810235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is loaded into a variable named 'train_data_df'\n",
    "# Example (uncomment and use if you need to load it):\n",
    "# train_data_df = pd.read_csv('your_file_name.csv')\n",
    "\n",
    "# Find columns where all values are NaN\n",
    "all_nan_cols = train_data_df.columns[train_data_df.isnull().all()]\n",
    "\n",
    "# Get the count of such columns\n",
    "num_all_nan_cols = len(all_nan_cols)\n",
    "\n",
    "# Print the results\n",
    "if num_all_nan_cols > 0:\n",
    "    print(f\"Found {num_all_nan_cols} columns with only NaN values.\")\n",
    "    print(\"These columns are:\")\n",
    "    \n",
    "    # Print the list of column names\n",
    "    for col_name in all_nan_cols:\n",
    "        print(col_name)\n",
    "else:\n",
    "    print(\"No columns were found with only NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your output filepaths\n",
    "train_output_fp = 'train_data_pre.parquet'\n",
    "test_output_fp = 'test_data_pre.parquet'\n",
    "\n",
    "print(f\"Saving merged training data to {train_output_fp}...\")\n",
    "# Use .to_parquet() to save\n",
    "# index=False is important to avoid saving the pandas index as a separate column\n",
    "train_data_df.to_parquet(train_output_fp, index=False)\n",
    "\n",
    "print(f\"Saving merged test data to {test_output_fp}...\")\n",
    "test_data_df.to_parquet(test_output_fp, index=False)\n",
    "\n",
    "print(\"Save complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f1da84",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b499c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import duckdb\n",
    "\n",
    "# os.chdir(r\"C:\\Users\\siddu\\Desktop\\Decision Science Track\\Revision\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a87c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload filepaths\n",
    "train_data_fp = r\"C:\\Users\\siddu\\Desktop\\Decision Science Track\\Revision\\train_data_pre.parquet\"\n",
    "test_data_fp = r\"C:\\Users\\siddu\\Desktop\\Decision Science Track\\Revision\\test_data_pre.parquet\"\n",
    "\n",
    "# Load files into dataframes\n",
    "train_data_df = pd.read_parquet(train_data_fp)\n",
    "test_data_df = pd.read_parquet(test_data_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65939b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns where all values are NaN\n",
    "all_nan_cols = train_data_df.columns[train_data_df.isnull().all()]\n",
    "\n",
    "# Get the count of such columns\n",
    "num_all_nan_cols = len(all_nan_cols)\n",
    "\n",
    "# Print the results\n",
    "if num_all_nan_cols > 0:\n",
    "    print(f\"Found {num_all_nan_cols} columns with only NaN values.\")\n",
    "    print(\"These columns are:\")\n",
    "    \n",
    "    # Print the list of column names\n",
    "    for col_name in all_nan_cols:\n",
    "        print(col_name)\n",
    "else:\n",
    "    print(\"No columns were found with only NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify col types\n",
    "binary_cols = ['y', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309']\n",
    "\n",
    "numeric_cols = ['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f43', 'f44', 'f45', 'f46', 'f47', 'f49', 'f51','f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f350', 'f351', 'f352', 'f353', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f375', 'f376', 'f377']\n",
    "\n",
    "categorical_cols = ['id3', 'id6','id8', 'id10', 'id11', 'f42', 'f48', 'f50', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f349', 'f354', 'f374', 'f378']\n",
    "\n",
    "datetime_cols = ['id4', 'id7', 'id12', 'id13', 'id5']\n",
    "\n",
    "object_cols = ['id1', 'id2', 'id9']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454117a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing all data types\n",
    "\n",
    "def process_all_data_types(df):\n",
    "    \"\"\"\n",
    "    Processes and converts all columns in a DataFrame based on predefined lists.\n",
    "    \"\"\"\n",
    "    print(\"Converting binary columns (float32)...\")\n",
    "    # This map is robust: handles '0'/'1' and 0/1.\n",
    "    # Anything else (like NaN, None, '') becomes <NA>\n",
    "    #binary_map = {'0': 0, '1': 1, 0: 0, 1: 1}\n",
    "    for col in binary_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int8')\n",
    "\n",
    "    print(\"Converting numeric columns (float32)...\")\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype('float32')\n",
    "\n",
    "    print(\"Converting datetime columns (datetime64[ns])...\")\n",
    "    for col in datetime_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "    print(\"Converting categorical columns (category)...\")\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    print(\"Cleaning and converting key object columns (string)...\")\n",
    "    for col in object_cols:\n",
    "        if col in df.columns:\n",
    "            # Clean and convert to modern 'string' dtype\n",
    "            df[col] = df[col].astype(str).str.strip().str.lower().astype('string')\n",
    "            \n",
    "    return df\n",
    "\n",
    "# --- Run Processing on Both DataFrames ---\n",
    "dataframes_to_process = {\n",
    "    'train': train_data_df,\n",
    "    'test': test_data_df\n",
    "}\n",
    "\n",
    "# Keep track of all columns we intended to process\n",
    "all_specified_cols = set(binary_cols) | set(numeric_cols) | set(categorical_cols) | set(datetime_cols) | set(object_cols)\n",
    "\n",
    "for name, df in dataframes_to_process.items():\n",
    "    print(f\"\\n--- Processing {name.upper()} DataFrame ---\")\n",
    "    \n",
    "    # Run the main conversion function\n",
    "    df = process_all_data_types(df)\n",
    "    \n",
    "    # --- Verification ---\n",
    "    print(f\"\\n--- {name.upper()} DataFrame .info() after conversion ---\")\n",
    "    df.info() # This will show us the new dtypes\n",
    "    \n",
    "    # Find any columns that were in the DataFrame but not in our lists\n",
    "    unprocessed_cols = set(df.columns) - all_specified_cols\n",
    "    \n",
    "    if unprocessed_cols:\n",
    "        print(f\"\\n⚠️ WARNING: The following {len(unprocessed_cols)} columns were not in any list:\")\n",
    "        print(unprocessed_cols)\n",
    "    else:\n",
    "        print(\"\\n✅ All columns were successfully processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns where all values are NaN\n",
    "all_nan_cols = train_data_df.columns[train_data_df.isnull().all()]\n",
    "\n",
    "# Get the count of such columns\n",
    "num_all_nan_cols = len(all_nan_cols)\n",
    "\n",
    "# Print the results\n",
    "if num_all_nan_cols > 0:\n",
    "    print(f\"Found {num_all_nan_cols} columns with only NaN values.\")\n",
    "    print(\"These columns are:\")\n",
    "    \n",
    "    # Print the list of column names\n",
    "    for col_name in all_nan_cols:\n",
    "        print(col_name)\n",
    "else:\n",
    "    print(\"No columns were found with only NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c645d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_df.info())\n",
    "print(test_data_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cbcb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check consistency of datatypes of train and test\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Assuming your DataFrames are loaded ---\n",
    "# train_data_df = ...\n",
    "# test_data_df = ...\n",
    "\n",
    "\n",
    "## 1. Group DataFrames for easy checking\n",
    "# Use a dictionary to map a name to the DataFrame object\n",
    "dataframes_to_check = {\n",
    "    'train': train_data_df,\n",
    "    'test': test_data_df\n",
    "}\n",
    "\n",
    "## 2. NEW: Automatically build the list of ALL unique columns\n",
    "print(\"Finding all unique columns across datasets...\")\n",
    "all_columns_set = set()\n",
    "for df in dataframes_to_check.values():\n",
    "    # .update() adds all columns from the DataFrame to the set\n",
    "    all_columns_set.update(df.columns)\n",
    "\n",
    "# Use this comprehensive list as your new cols_to_check\n",
    "# Sorting makes the final report easier to read\n",
    "cols_to_check = sorted(list(all_columns_set))\n",
    "print(f\"Found {len(cols_to_check)} unique columns to check.\")\n",
    "\n",
    "\n",
    "## 3. Store findings in a dictionary\n",
    "# The key will be the column name\n",
    "# The value will be a set of all dtypes found\n",
    "column_dtypes = defaultdict(set)\n",
    "\n",
    "## 4. Iterate and check\n",
    "print(\"\\nChecking column data types...\")\n",
    "for col in cols_to_check:\n",
    "    for df_name, df in dataframes_to_check.items():\n",
    "        # Check if the column exists in the DataFrame\n",
    "        if col in df.columns:\n",
    "            # If it exists, add its dtype (as a string) to the set\n",
    "            column_dtypes[col].add(str(df[col].dtype))\n",
    "\n",
    "## 5. Report the results\n",
    "print(\"\\n--- Dtype Consistency Report ---\")\n",
    "inconsistent_cols = []\n",
    "\n",
    "for col, dtypes in column_dtypes.items():\n",
    "    # Note: A column will ONLY show up here if it exists\n",
    "    # in at least one of the DataFrames.\n",
    "    \n",
    "    if len(dtypes) == 1:\n",
    "        # Only one dtype was found, so it's consistent\n",
    "        print(f\"✅ {col:<20} | Consistent: {list(dtypes)[0]}\")\n",
    "    else:\n",
    "        # More than one dtype was found, this is an inconsistency\n",
    "        print(f\"⚠️ {col:<20} | INCONSISTENT: {dtypes}\")\n",
    "        inconsistent_cols.append(col)\n",
    "\n",
    "print(\"\\n--- Summary ---\")\n",
    "if not inconsistent_cols:\n",
    "    print(\"All checked columns are consistent across datasets.\")\n",
    "else:\n",
    "    print(f\"Found {len(inconsistent_cols)} inconsistent columns: {inconsistent_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d400dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Assuming your merged DataFrames are in memory ---\n",
    "\n",
    "# Define your output filepaths\n",
    "train_output_fp = 'train_data_cols_sorted.parquet'\n",
    "test_output_fp = 'test_data_cols_sorted.parquet'\n",
    "\n",
    "print(f\"Saving training data to {train_output_fp}...\")\n",
    "# Use .to_parquet() to save\n",
    "# index=False is important to avoid saving the pandas index as a separate column\n",
    "train_data_df.to_parquet(train_output_fp, index=False)\n",
    "\n",
    "print(f\"Saving test data to {test_output_fp}...\")\n",
    "test_data_df.to_parquet(test_output_fp, index=False)\n",
    "\n",
    "print(\"Save complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
